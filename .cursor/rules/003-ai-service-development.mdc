---
description: "AI service development rules to prevent mock mode issues and ensure real AI responses"
globs:
  - "agent/**/*"
  - "**/ai/**/*"
  - "**/langchain/**/*"
alwaysApply: true
---

# ü§ñ AI Service Development Rules (Priority 3)

## üéØ Core Principle: Real AI Responses Only

### ‚ùå NEVER DO THIS
- Ship AI services with mock responses in production
- Use placeholder API keys (`'test-key'`, `'your_openai_api_key_here'`)
- Allow services to silently fall back to mock mode
- Deploy AI services without validating API connectivity
- Use hardcoded responses that end with "..." or ellipsis

### ‚úÖ ALWAYS DO THIS
- **API Key Validation**: Validate OpenAI API keys at startup
- **Mock Mode Detection**: Detect and warn when running in mock mode
- **Production Guards**: Prevent mock mode in production environments
- **Real Responses**: Use actual AI models for all user-facing responses
- **Error Handling**: Graceful degradation when AI services are unavailable

## üîß AI Service Configuration

### Environment Validation
```typescript
// ‚úÖ GOOD: Validate API keys at startup
const isMockMode = config.openaiApiKey === 'test-key' || 
                   !config.openaiApiKey || 
                   config.openaiApiKey === 'your_openai_api_key_here';

if (isMockMode) {
  console.warn('‚ö†Ô∏è  WARNING: AI service running in MOCK MODE!');
  console.warn('‚ö†Ô∏è  You will get fake responses instead of real AI responses.');
  console.warn('‚ö†Ô∏è  Set valid OPENAI_API_KEY to get real AI responses.');
  
  if (process.env.NODE_ENV === 'production') {
    throw new Error('Cannot run AI service in mock mode in production');
  }
}
```

### Service Health Checks
```typescript
// ‚úÖ GOOD: Health check endpoint
app.get('/health', async (req, res) => {
  const isHealthy = !isMockMode && await testAIConnectivity();
  
  res.json({
    status: isHealthy ? 'healthy' : 'degraded',
    mockMode: isMockMode,
    aiProvider: 'openai',
    timestamp: new Date().toISOString()
  });
});
```

## üõ°Ô∏è Prevention Patterns

### Mock Response Detection
```typescript
// ‚úÖ GOOD: Detect mock responses
function isMockResponse(content: string): boolean {
  const mockPatterns = [
    /\.\.\.$/,  // Ends with ellipsis
    /suggestions\.\.\./,  // Contains "suggestions..."
    /Here are some.*\.\.\./,  // Generic mock patterns
  ];
  
  return mockPatterns.some(pattern => pattern.test(content));
}

// ‚úÖ GOOD: Warn about mock responses
if (isMockResponse(response.content)) {
  console.warn('‚ö†Ô∏è  Detected mock response pattern');
}
```

### Production Environment Guards
```typescript
// ‚úÖ GOOD: Production environment validation
if (process.env.NODE_ENV === 'production') {
  if (isMockMode) {
    throw new Error('Production AI service cannot run in mock mode');
  }
  
  if (!config.openaiApiKey || config.openaiApiKey.startsWith('sk-') === false) {
    throw new Error('Production requires valid OpenAI API key');
  }
}
```

## üö® Red Flags in AI Services

### Code Red Flags
- `generateMockResponse()` functions in production code
- `isMockMode = true` without environment checks
- Hardcoded responses ending with "..."
- Missing API key validation

### Runtime Red Flags
- Responses that don't match user input
- Generic responses like "Here are some suggestions..."
- Truncated responses ending with ellipsis
- Missing LangSmith traces

### Configuration Red Flags
- `OPENAI_API_KEY=test-key` in production
- Missing environment validation
- No health check endpoints
- Silent fallbacks to mock mode

## üéØ Success Criteria
- **AI services always use real models in production**
- **Clear warnings when running in mock mode**
- **Health checks validate AI connectivity**
- **Production deployments fail fast if misconfigured**
- **Real AI responses match user input context**
- **Observability traces show real AI usage**

## üîß Implementation Checklist

### Before Development
- [ ] Set real OpenAI API key in `.env`
- [ ] Run `npm run setup` to validate configuration
- [ ] Check service starts without mock mode warnings
- [ ] Test AI connectivity with health check

### Before Deployment
- [ ] Verify no mock mode warnings in logs
- [ ] Confirm AI responses are contextual and complete
- [ ] Check LangSmith traces are being created
- [ ] Validate health check endpoint works

### After Deployment
- [ ] Test end-to-end AI functionality
- [ ] Verify responses are real and contextual
- [ ] Check observability traces
- [ ] Monitor for mock response patterns

---

*This rule ensures AI services use real models and prevents mock mode issues in production.*